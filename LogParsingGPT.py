import random
import openai
import os
import re

from tqdm import tqdm

instruction = """
You are an AI log analysis expert. You should look a log message given by user then generate python code including variable assigning lines and f-string template assigining line. If there are no semantic variable names in this log message, template should be same as the log message. The generated code should generate the user's input log. Followings are examples:
EXAMPLES:
{examples}
END EXAMPLES
""".strip()

examples = [
    "USER: 'workerEnv.init() ok /etc/httpd/conf/workers2.properties'",
    "ASSISTANT: path = '/etc/httpd/conf/workers2.properties'\ntemplate = f'workerEnv.init() ok {path}'\n",
    "USER: 'Listing instance in cell 949e1227'",
    "ASSISTANT: cell_id = '949e1227'\ntemplate = f'Listing instance in cell {cell_id}'\n",
    "USER: 'ss.bdimg.com:80 error : Could not connect to proxy proxy.cse.cuhk.edu.hk:5070 - Could not resolve proxy.cse.cuhk.edu.hk error 11001'",
    "ASSISTANT: host = 'ss.bdimg.com'\nhost_port = '80'\nproxy = 'proxy.cse.cuhk.edu.hk'\nproxy_port = '5070'\nerror_cde = '11001'\ntemplate = f'{host}:{host_port} error : Could not connect to proxy {proxy}:{proxy_port} - Could not resolve proxy {proxy} error {error_code}'",
    "USER: 'onReceive action: android.intent.action.SCREEN_ON'",
    "ASSISTANT: template = f'onReceive action: android.intent.action.SCREEN_ON'"
]

second_instruction = """
SAMPLES: {samples}
Second, above are sample log messages generated by the template you've generated. Determine if the template needs to be updated by determining if the template is correct and that the variable names are well-constructed to represent the log messages.
""".strip()

third_instruction = """
Third, you should update the template to make it more generic and meaningful. The template should still be able to generate the sample log messages.
""".strip()

class LogParsingGPT:
    def __init__(self, openai_api_key: str = None) -> None:
        openai.api_key = openai_api_key or os.environ.get('OPENAI_API_KEY')
        self.model = 'gpt-3.5-turbo'

        self.instruction = instruction
        self.examples = examples
        self.second_instruction = second_instruction
        self.third_instruction = third_instruction
        self.messages = [{"role": "system", "content": instruction.format(examples='\n'.join(self.examples))}]

    def llm_run(self, user_prompt: str) -> str:
        response = openai.ChatCompletion.create(
            model=self.model,
            top_p=1,
            messages=self.messages + [{"role": "user", "content": user_prompt}]
        )
        return response['choices'][0]['message']['content']
        
    def output_parse(self,llm_output: str) -> dict:
        llm_output = llm_output.replace('ASSISTANT:\n', '')
        *variables, template = llm_output.split('\n')
        try:
            before = locals().copy()
            exec('\n'.join(variables))
            after = locals().copy()
            variables = {k: after[k] for k in after if k not in before and k != 'before'}
            
        except Exception as e:
            print("ERROR:",e)
            print(llm_output)
            exit(0)

        try:
            template = template.split('=')[1].strip()
            # remove f-string
            template = template[2:-1]
            # remove all '\' from template
            template = template.replace('\\', '')
        except Exception as e:
            print("ERROR:",e)
            print(llm_output)
            exit(0)

        return {'variables': variables, 'template': template}
    
    def yes_or_no(self, llm_output: str) -> bool:
        if llm_output.lower().startswith('yes'):
            return True
        elif llm_output.lower().startswith('no'):
            return False
        else:
            raise ValueError('llm_output should start with yes or no')
        
def check_substring_set(string, substring_set):
    current_index = 0
    for substring in substring_set:
        substring_index = string.find(substring, current_index)
        if substring_index == -1:
            return False
        current_index = substring_index + len(substring)
    return True
       
def match_template(logs: list[str], template: str):
    stared_template = var_to_star(template)
    return [ log for log in logs if check_substring_set(log, stared_template.split('<*>'))]
     
def replace_variable(string):
    pattern = r'{(.*?)}'  # '{variable_name}' 패턴을 정규식으로 표현
    replaced_string = re.sub(pattern, r'<*>', string)
    return replaced_string

def var_to_star(template: str) -> str:
    replaced_template = replace_variable(template)
    return replaced_template

def run(logs: list[str]):
    log_parser = LogParsingGPT()
    result = {}
    logset = set(logs)
    all_matches = set()
    total = len(logset)
    for unique_log in logset:
        if unique_log in all_matches:
            continue
        print(f'Parsed {len(all_matches)}/{total} logs')
        llm_output = log_parser.llm_run(f"'{unique_log}'")
        output = log_parser.output_parse(llm_output)
        matches = match_template(list(logset), output['template'])
                
        result[output['template']] = {
            'variables': output['variables'],
            'matches': matches,
        }
        all_matches.update(matches)
        
    print(f'Parsed {len(result)} templates from {total} logs')
    for t in result:
        print(t)
    return result, logset - all_matches

def duplicate_template(templates: list[str]):
    for t in templates:
        result = match_template(templates, t)
        if len(result) > 1:
            print(t)
            print([ r for r in result if r != t])
                

def revisit_template(logs: list[str], stared_template: str):
    # 교집합이 있는 경우, 
    return [ log for log in logs if check_substring_set(log, stared_template.split('<*>'))]
        
if __name__ == '__main__':
    from data_utils import load_dataset
    import argparse
    import json

    parser = argparse.ArgumentParser()
    parser.add_argument('--dataset', type=str, required=True)
    parser.add_argument('--read', type=bool, default=False)
    parser.add_argument('--auto', type=bool, default=False, help='No need to confirm')
    args = parser.parse_args()

    if args.read:
        with open(f'result_{args.dataset}.json', 'r') as f:
            result = json.load(f)

        duplicate_template(result.keys())
        exit(0)

    test_data = load_dataset(args.dataset)
    logs = test_data['log'].tolist()
    random.shuffle(logs)
    result, logs = run(logs)

    duplicate_template(result.keys())

    # test_templates = test_data['template'].unique()

    # if not args.auto:
    #     confirm = input(f'You are going to parse {len(test_templates)} templates from {args.dataset}. Continue? (y/n) ')
    #     if confirm.lower() != 'y':
    #         exit(0)

    # log_parser = LogParsingGPT()

    # result = []

    # for template in tqdm(test_templates):
    #     log_messages = test_data[test_data['template'] == template]
    #     log_messages = log_messages['log'].tolist()

    #     sample_log = random.choice(log_messages)
    #     print(f'Parsing [{template}] \nfrom [{sample_log}]')

    #     llm_output = log_parser.llm_run(f"'{sample_log}'")
    #     output = log_parser.output_parse(llm_output)

    #     regex_template = sem_to_regex(output['template'], list(output['variables'].keys()))
    #     matches = match_template(log_messages, regex_template)
    #     output['oracle'] = template
    #     output['sample_log'] = sample_log
    #     output['accuracy'] = len(matches) / len(log_messages)
    #     output['unmatched'] = [ log for log in log_messages if log not in matches ]
    #     output['wrong_matches'] = [ log for log in matches if log not in log_messages ]
    #     result.append(output)
    #     print(f'Parsed [{output["template"]}] with Variables [{output["variables"]}]\nfrom [{sample_log}]')
    #     print(regex_template)
    #     print(f'Matches: {len(matches)} / {len(log_messages)}')
    #     print('----------------------------------')
    
    # sve result to file
    import json
    with open(f'result_{args.dataset}.json', 'w') as f:
        json.dump(result, f, indent=4)

    with open(f'left_{args.dataset}.txt', 'w') as f:
        f.write('\n'.join(logs))

